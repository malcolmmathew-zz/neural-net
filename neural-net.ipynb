{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for Neural Networks\n",
    "\n",
    "The purpose of this notebook is to create an implementation of a simple  artificial neural network for learning purposes. \n",
    "\n",
    "Here are the main concepts associated with an ANN:\n",
    "- Activation Function \n",
    "- Forward Propagation\n",
    "- Gradient Descent\n",
    "- Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(([3,5, 8],[5,1, 10],[10,2, 4]), dtype=float)\n",
    "y = np.array(([75],[82],[93]), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X = X/np.amax(X, axis=0)\n",
    "y = y/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3,  1. ,  0.8],\n",
       "       [ 0.5,  0.2,  1. ],\n",
       "       [ 1. ,  0.4,  0.4]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NeuralNet(object):\n",
    "    def __init__(self):\n",
    "        self.num_layers = 3\n",
    "        self.input_layer_size = 3\n",
    "        self.output_later_size = 1\n",
    "        self.hidden_layer_size  = 3\n",
    "        \n",
    "#         self.w = []\n",
    "#         for i in range(num_layers-1):\n",
    "#             self.w[i] = np.random.randn(self.arr[i], self.arr[i+1])\n",
    "        self.w1 = np.random.randn(self.input_layer_size, self.hidden_layer_size)\n",
    "        self.w2 = np.random.randn(self.hidden_layer_size, self.output_later_size)\n",
    "        self.w = [self.w1, self.w2]\n",
    "       \n",
    "#     def forward_propagation(self, X):\n",
    "#         self.z2 = np.dot(X, self.w1)\n",
    "#         self.a2 = self.sigmoid(self.z2)\n",
    "#         self.z3 = np.dot(self.a2, self.w2)\n",
    "#         self.y_hat = self.sigmoid(self.z3)\n",
    "        \n",
    "#         return self.y_hat\n",
    "    \n",
    "    def forward_propagation(self, X):\n",
    "        for l in range(self.num_layers-1):\n",
    "            if l == 0:\n",
    "                node_in = X\n",
    "            else:\n",
    "                node_in = h   \n",
    "                print \"printh\"\n",
    "            z = np.dot(self.w[l],node_in) # + b[l] add bias later\n",
    "#             print self.w[l].shape\n",
    "#             print node_in.shape\n",
    "            h = self.sigmoid(z)\n",
    "            print h.shape\n",
    "            \n",
    "        return h\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def sigmoid_derivative(self, z):\n",
    "        return np.exp(-z)/(1+np.exp(-z)**2)\n",
    "    \n",
    "    def cost_function_derivative(self, X, y):\n",
    "        self.y_hat = self.forward_propagation(X)\n",
    "        \n",
    "        delta3 = np.multiply(-(y-self.y_hat), self.sigmoid_derivative(self.z3))\n",
    "        dj_dw2 = np.dot(self.a2.T, delta3)\n",
    "        \n",
    "        delta2 = np.dot(delta3, self.w2.T)*self.sigmoid_derivative(self.z2)\n",
    "        dj_dw1 = np.dot(X.T, delta2)\n",
    "        \n",
    "        return dj_dw1, dj_dw2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few important parts to building out a basic Artificial Neural Network. The first thing to do is define the concept of an activation/sigmoid function.\n",
    "\n",
    "$$f(z)= \\frac{1}{1+\\exp(-x)}$$\n",
    "\n",
    "This is the function applied to the inputs of all nodes in the network  and its result is passed to the next layer as an input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(self, z):\n",
    "    \"\"\"Given an input, returns the result of the sigmoid function.\"\"\"\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This activation function has a weight assigned to its input for each individual connection from one node to another. The sum of these results become the output to feed into the next layer of nodes. This concept is called forward propagation.\n",
    "\n",
    "Implementation-wise, we use numpy arrays and matrix operations to make this function simpler and more time-efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(self, X):\n",
    "    self.z2 = np.dot(X, self.w1)\n",
    "    self.a2 = self.sigmoid(self.z2)\n",
    "    self.z3 = np.dot(self.a2, self.w2)\n",
    "    self.y_hat = self.sigmoid(self.z3)\n",
    "\n",
    "    return self.y_hat\n",
    "\n",
    "def matrix_feed_forward_calc(self, X):\n",
    "    for l in range(num_layers-1):\n",
    "        if l == 0:\n",
    "            node_in = x\n",
    "        else:\n",
    "            node_in = h\n",
    "        z = self.w[l].dot(node_in) # + b[l] add bias later\n",
    "        h = f(z)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(self, z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "printh\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (3,1) and (3,3) not aligned: 1 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-593ebbbcbb78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mNN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-74-a772a18acb07>\u001b[0m in \u001b[0;36mforward_propagation\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mnode_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[1;32mprint\u001b[0m \u001b[1;34m\"printh\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnode_in\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# + b[l] add bias later\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;31m#             print self.w[l].shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m#             print node_in.shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (3,1) and (3,3) not aligned: 1 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "NN = NeuralNet()\n",
    "\n",
    "print NN.forward_propagation(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NN  = Neural_Net()\n",
    "\n",
    "c1 = NN.cost_function_derivative(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " a,b = NN.cost_function_derivative(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06366729,  0.02766799,  0.25473514],\n",
       "       [-0.04287048,  0.01929333,  0.18918441]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2191875 ],\n",
       "       [-0.32555071],\n",
       "       [-0.19873838]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$c = \\sqrt{a^2 + b^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
